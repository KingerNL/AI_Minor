{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Argmax() functie"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\r\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "z = [2.0, 1.0, 3.0, 4.0, 5.0, 2.0]\r\n",
    "\r\n",
    "print(np.argmax(z, axis=None)) #print: positie van het grootste getal\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Argmax is erg handig te gebruiken om te kijken welk getal in een array het hoogst is. Men kan dit gebruiken bij een neuraal netwerk om zo (snel) te bepalen welke target het hoogst is."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MSE (Mean squared error)\n",
    "\n",
    "De MSE maakt een schatting van de gemiddelde fout. Dit is het gemiddelde afstand van de geschatte waarde tot de daadwerkelijke waarde.\n",
    "En dat dan in kwadraat. Als reden om zo de fout nog duidelijker te visualizeren."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from sklearn.metrics import mean_squared_error\r\n",
    "  \r\n",
    "Y_true = [1,2,2.5,2.5,3.4] # \"echte\" waardes: (deze heb ik bedacht)\r\n",
    "  \r\n",
    "Y_pred = [0.6,1.29,1.99,2.69,3.4]  # Verzonnen waardes, deze kan een algoritme bijvoorbeeld geven.\r\n",
    "  \r\n",
    "mean_squared_error(Y_true, Y_pred) # Berekent de mean_squared_error "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.19206"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "Y_true = [1,2,3,4,5]\r\n",
    "  \r\n",
    "Y_pred = [1,2,3,4,6] # alleen de 5 is naar een 6 verranderd nu\r\n",
    "  \r\n",
    "mean_squared_error(Y_true, Y_pred)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "0.2 klopt! Omdat: (6-5)^2 / 5 = 0.2!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Categorical crossentropy\n",
    "\n",
    "Hoewel Categorical crossentropy wat ingewikkelder is dan de Mean squared error te berekenen werkt het erg goed. Het heeft wel een Softmax / Sigmoid functie nodig om het aan te sturen. Hoewel de Mean squared error veel wordt gebruikt om **predictions** te geven wordt Categorical crossentropy gebruikt voor **Classification**. Als je weet wat Softmax doet klinkt dit erg logisch.\n",
    "\n",
    "Categorical crossentropy wordt vaak gebruikt wanneer je een list met getallen tussen de 0 en 1 heeft, waarbij 1 het meest geschikt is en 0 het minst. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Als je een leuk stukje code wil zien waar Categorical crossentropy wordt gebruikt. Klinkt [Hier](https://gitlab.fdmci.hva.nl/veldkam3/bootcamp/-/blob/master/bootcamp/dag7/dag7_ochtend.ipynb)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}